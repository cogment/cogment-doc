"use strict";(self.webpackChunkcogment_doc=self.webpackChunkcogment_doc||[]).push([[346],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=s(n),m=r,h=d["".concat(p,".").concat(m)]||d[m]||u[m]||o;return n?a.createElement(h,i(i({ref:t},c),{},{components:n})):a.createElement(h,i({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=d;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var s=2;s<o;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},8861:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var a=n(7462),r=(n(7294),n(3905));const o={},i="Step 5: Add a human player in the loop",l={unversionedId:"guide/tutorial/human-player",id:"guide/tutorial/human-player",title:"Step 5: Add a human player in the loop",description:"This part of the tutorial follows step 4, make sure you've gone through it before starting this one. Alternatively the completed step 4 can be retrieved from the tutorial's repository.",source:"@site/docs/guide/tutorial/5-human-player.md",sourceDirName:"guide/tutorial",slug:"/guide/tutorial/human-player",permalink:"/docs/guide/tutorial/human-player",draft:!1,tags:[],version:"current",lastUpdatedAt:1657553723,formattedLastUpdatedAt:"Jul 11, 2022",sidebarPosition:5,frontMatter:{},sidebar:"docSidebar",previous:{title:"Step 4: Add a second actor implementation based on a heuristic",permalink:"/docs/guide/tutorial/heuristic-player"},next:{title:"Step 6: Add a web client for the human player",permalink:"/docs/guide/tutorial/web-client"}},p={},s=[{value:"Client actor implementation",id:"client-actor-implementation",level:2},{value:"Interactive prompt to let Humans play RPS",id:"interactive-prompt-to-let-humans-play-rps",level:2}],c={toc:s};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"step-5-add-a-human-player-in-the-loop"},"Step 5: Add a human player in the loop"),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"This part of the tutorial follows ",(0,r.kt)("a",{parentName:"p",href:"/docs/guide/tutorial/heuristic-player"},"step 4"),", make sure you've gone through it before starting this one. Alternatively the completed step 4 can be retrieved from the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/cogment/cogment-tutorial-rps"},"tutorial's repository"),".")),(0,r.kt)("p",null,"In this step of the tutorial, we will go over another actor implementation, this time client-side, to enable Humans to play RPS."),(0,r.kt)("h2",{id:"client-actor-implementation"},"Client actor implementation"),(0,r.kt)("p",null,"To involve a human player in our trials, we will add a specific actor implementation in the client. While the previous ",(0,r.kt)("strong",{parentName:"p"},"service actor")," implementations are exposing endpoints Cogment's orchestrator connects to in order to run a trial, this ",(0,r.kt)("strong",{parentName:"p"},"client actor")," implementation connects to the orchestrator to join a trial. It changes a lot under the hood and enables interesting network topology because only the client needs to know how to reach the orchestrator, not the other way around. However, as you'll see, in terms of implementation it is very similar."),(0,r.kt)("p",null,"This actor implementation will be located in the client code in ",(0,r.kt)("inlineCode",{parentName:"p"},"client/main.py")),(0,r.kt)("p",null,"We first need to import the data structures needed to send actions."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from data_pb2 import PlayerAction, ROCK, PAPER, SCISSORS\n\nMOVES = [ROCK, PAPER, SCISSORS]\nMOVES_STR = ["\ud83d\udc4a rock", "\u270b paper", "\u270c\ufe0f scissors"]\nMOVES_PROMPT = \', \'.join([ f"{name} ({idx})" for idx, name in enumerate(MOVES_STR)])\n')),(0,r.kt)("p",null,"In the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," function we then implement the ",(0,r.kt)("inlineCode",{parentName:"p"},"human_player")," actor implementation, only playing ",(0,r.kt)("inlineCode",{parentName:"p"},"PAPER")," for the moment, register the implementation and join the trial once it is initialized."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'context = cogment.Context(cog_settings=cog_settings, user_id="rps")\n\nasync def human_player(actor_session):\n    round_index = 0\n\n    actor_session.start()\n\n    async for event in actor_session.all_events():\n        if event.observation:\n            observation = event.observation\n\n            if event.type == cogment.EventType.ACTIVE:\n                print(f"\\n-- Round #{round_index + 1} --\\n")\n\n                next_action = PlayerAction(move=PAPER)\n                actor_session.do_action(next_action)\n\n                round_index += 1\n\ncontext.register_actor(\n    impl=human_player,\n    impl_name="human",\n    actor_classes=["player"])\n')),(0,r.kt)("p",null,"We update the configuration of the first actor to use ",(0,r.kt)("em",{parentName:"p"},"special")," endpoint, ",(0,r.kt)("inlineCode",{parentName:"p"},'"cogment://client"'),", which tells the orchestrator to wait for a client to connect to it. We also don't need to specify an implementation name."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'actor_1_params = cogment.ActorParameters(\n    cog_settings,\n    name="player_1",\n    class_name="player",\n    endpoint="cogment://client"\n)\n')),(0,r.kt)("p",null,"Because the client actor will be active during the trial, we no longer need to use ",(0,r.kt)("inlineCode",{parentName:"p"},"watch_trials")," to await trial termination but simply need to await ",(0,r.kt)("inlineCode",{parentName:"p"},"context.join_trial")," completion."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Defining the trial id on the client side\ntrial_id=f"rps-{datetime.datetime.now().isoformat()}"\n\n# Start a new trial using the trial params we just created\ntrial_id = await controller.start_trial(trial_id_requested=trial_id, trial_params=trial_params)\nprint(f"Trial \'{trial_id}\' started")\n\n# Let the human actor join the trial\nawait context.join_trial(trial_id=trial_id, endpoint=cogment.Endpoint(ORCHESTRATOR_ENDPOINT), actor_name="player_1")\nprint(f"Trial \'{trial_id}\' ended")\n')),(0,r.kt)("p",null,"Modify the ",(0,r.kt)("inlineCode",{parentName:"p"},"client/main.py")," file with these updates."),(0,r.kt)("p",null,"You can now ",(0,r.kt)("a",{parentName:"p",href:"/docs/guide/tutorial/bootstrap-and-data-structures#building-and-running-the-app"},"build and run")," the application. Everything should work but player 1 shouldn't fare too well as it only ever plays ",(0,r.kt)("inlineCode",{parentName:"p"},"PAPER"),"."),(0,r.kt)("h2",{id:"interactive-prompt-to-let-humans-play-rps"},"Interactive prompt to let Humans play RPS"),(0,r.kt)("p",null,"Let's add a text user interface to our client in order to finally challenge AIs to a game of RPS."),(0,r.kt)("p",null,"First we'll want to display what was played in the previous round. We will implement a dedicated function ",(0,r.kt)("inlineCode",{parentName:"p"},"print_observation"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'def print_observation(observation):\n    print(f"\ud83e\uddd1 played {MOVES_STR[observation.observation.me.last_move]}")\n    print(f"\ud83e\udd16 played {MOVES_STR[observation.observation.them.last_move]}")\n    if observation.observation.me.won_last:\n        print(f" -> \ud83e\uddd1 wins round #{round_index + 1}")\n    elif observation.observation.them.won_last:\n        print(f" -> \ud83e\udd16 wins the round #{round_index + 1}")\n    else:\n        print(f" -> round #{round_index + 1} is a draw")\n')),(0,r.kt)("p",null,"It needs to be called whenever the actor receives an observation, except for the first time, before the first round is played. Add the following just after the observation is retrieved in the event loop."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"if round_index > 0:\n  # The only time the observation is not relevant is on the first round of the first game\n  print_observation(observation)\n")),(0,r.kt)("p",null,"Last but not least, instead of always picking ",(0,r.kt)("inlineCode",{parentName:"p"},"PAPER")," we will read from the keyboard input what the player wishes to play. Using python's ",(0,r.kt)("a",{parentName:"p",href:"https://docs.python.org/3.7/library/functions.html#input"},(0,r.kt)("inlineCode",{parentName:"a"},"input"))," function we can print a prompt and read whatever the user enters before pressing ",(0,r.kt)("inlineCode",{parentName:"p"},"<ENTER>"),"."),(0,r.kt)("p",null,"Note that the following implementation expects a number between 1 and 3 and doesn't handle well any other input."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"move = MOVES[int(input(MOVES_PROMPT))]\nnext_action = PlayerAction(move=move)\n")),(0,r.kt)("p",null,"Modify the ",(0,r.kt)("inlineCode",{parentName:"p"},"client/main.py")," file to include the above additions."),(0,r.kt)("p",null,"You can now ",(0,r.kt)("a",{parentName:"p",href:"/docs/guide/tutorial/bootstrap-and-data-structures#building-and-running-the-app"},"build and run")," the application. You'll be presented with a prompt for choosing your moves and comparing your skills to the simple heuristic AI we implemented earlier."),(0,r.kt)("p",null,"This concludes the step 5 of the tutorial: you implemented your first client actor and put your first human in the loop! This is also the final step for the basics tutorial."),(0,r.kt)("p",null,"You can continue by implementing a web client to replace the command line interface we just developed in ",(0,r.kt)("a",{parentName:"p",href:"/docs/guide/tutorial/web-client"},"step 6"),". You can also learn how to train an actor implementation using Reinforcement Learning in ",(0,r.kt)("a",{parentName:"p",href:"/docs/guide/tutorial/dqn-player"},"step 7"),"."))}u.isMDXComponent=!0}}]);